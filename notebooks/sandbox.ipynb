{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, load_from_disk, concatenate_datasets, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_metamathqa(examples, prefix=\"Please answer the following question: \"):\n",
    "    \"\"\"Add a prefix to the inputs and tokenize the inputs and targets.\n",
    "\n",
    "    Args:\n",
    "        examples: dataset examples.\n",
    "        tokenizer: tokenizer.\n",
    "        prefix (str, optional): Prefix to add to each inputs. Defaults to \"Please answer the following question: \".\n",
    "\n",
    "    Returns:\n",
    "        dataset: processed examples.\n",
    "    \"\"\"\n",
    "    # The \"inputs\" are the tokenized answer:\n",
    "    inputs = [prefix + doc for doc in examples[\"query\"]]\n",
    "\n",
    "    labels = examples[\"response\"]\n",
    "    return {\"question\": inputs, \"answer\": labels}\n",
    "\n",
    "def load_metamathqa(dev_mode=False):\n",
    "    \"\"\"Load the metamathqa dataset.\n",
    "\n",
    "    Returns:\n",
    "        Dataset: metamathqa dataset.\n",
    "    \"\"\"\n",
    "    dataset = load_dataset(\"meta-math/MetaMathQA\")\n",
    "    if dev_mode:\n",
    "        dataset[\"train\"] = dataset[\"train\"].select(range(20))  # For development\n",
    "    else:\n",
    "        dataset[\"train\"] = dataset[\"train\"].select(range(50000))  # For fine-tuning\n",
    "    dataset = dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "    tokenized_dataset = dataset.map(\n",
    "        process_metamathqa,\n",
    "        batched=True,\n",
    "        remove_columns=[\"query\", \"response\", \"type\", \"original_question\"],\n",
    "    )\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 16/16 [00:00<00:00, 7240.14 examples/s]\n",
      "Map: 100%|██████████| 4/4 [00:00<00:00, 2385.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_class = load_from_disk(\"../datasets/class_sft_datasetdict\")\n",
    "metamath_qa = load_metamathqa(dev_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict()\n",
    "dataset['train'] = concatenate_datasets([dataset_class['train'], metamath_qa['train']]).shuffle(seed=42)\n",
    "dataset['test'] = concatenate_datasets([dataset_class['test'], metamath_qa['test']]).shuffle(seed=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
